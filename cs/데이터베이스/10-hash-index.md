# 해시 인덱스 (Hash Index)

## 개요

해시 인덱스는 **해시 함수를 사용하여 키를 버킷에 매핑**하는 인덱스 구조다. 이상적인 경우 **O(1)** 시간에 검색이 가능하지만, **범위 검색이 불가능**하고 **해시 충돌**과 **동적 크기 조절** 문제가 있다. 이 문서에서는 Static Hashing의 한계와 Extendible Hashing, Linear Hashing 등 동적 해싱 기법을 다룬다.

## 핵심 개념

### 1. 해시 인덱스 기본 구조

```
┌─────────────────────────────────────────────────────────────┐
│                    Hash Index Structure                      │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Key → Hash Function → Bucket Number → Bucket → Data       │
│                                                             │
│   h(key) = key mod N   (N = 버킷 수)                        │
│                                                             │
│   예: h(25) = 25 mod 4 = 1                                  │
│                                                             │
│   ┌─────────┐                                               │
│   │ Bucket 0│ → [4*, 8*, 12*]                               │
│   │ Bucket 1│ → [1*, 5*, 25*]                               │
│   │ Bucket 2│ → [2*, 6*, 10*]                               │
│   │ Bucket 3│ → [3*, 7*, 15*]                               │
│   └─────────┘                                               │
│                                                             │
│   * = 데이터 포인터                                          │
└─────────────────────────────────────────────────────────────┘
```

### 2. Static Hashing의 한계

```
┌─────────────────────────────────────────────────────────────┐
│              Static Hashing 문제점                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│ 1. 버킷 오버플로 (Bucket Overflow)                          │
│    - 해시 충돌이 많으면 버킷이 넘침                          │
│    - 오버플로 체인으로 해결 → 성능 저하                      │
│                                                             │
│    ┌─────────┐    ┌─────────┐    ┌─────────┐              │
│    │ Bucket 1│ →  │Overflow1│ →  │Overflow2│              │
│    └─────────┘    └─────────┘    └─────────┘              │
│                                                             │
│ 2. 공간 낭비                                                 │
│    - 데이터가 적으면 빈 버킷이 많음                          │
│    - 초기에 큰 버킷 배열 할당 필요                           │
│                                                             │
│ 3. 재해싱 비용                                               │
│    - 버킷 수 변경 시 모든 데이터 재해싱                      │
│    - O(N) 비용, 서비스 중단                                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 3. Extendible Hashing

동적으로 버킷을 분할하여 오버플로 없이 확장:

```
┌─────────────────────────────────────────────────────────────┐
│              Extendible Hashing                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│ 구조:                                                        │
│ - Directory: 2^global_depth 개의 포인터 배열                │
│ - Bucket: 각각 local_depth를 가짐                           │
│                                                             │
│ Global Depth = 2                                            │
│ ┌───────────────────┐                                       │
│ │  Directory        │                                       │
│ │  00 → │  Bucket A │ (local_depth=2)                      │
│ │  01 → │  Bucket B │ (local_depth=2)                      │
│ │  10 → │  Bucket C │ (local_depth=1)  ← 10, 11이 공유     │
│ │  11 → ┘           │                                       │
│ └───────────────────┘                                       │
│                                                             │
│ 검색: h(key)의 하위 global_depth 비트로 디렉토리 인덱스      │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**버킷 분할 과정:**

```
예: Bucket C (local_depth=1, 10/11 공유)가 가득 참

Before:
Global Depth = 2
10 ─┐
11 ─┴─→ Bucket C [10*, 26*, 18*, 11*]  (full, local=1)

After:
Global Depth = 2
10 ───→ Bucket C' [10*, 26*, 18*]  (local=2, 끝이 10)
11 ───→ Bucket C''[11*]            (local=2, 끝이 11)

local_depth < global_depth이면 디렉토리 포인터만 분리
local_depth = global_depth이면 디렉토리도 2배로 확장
```

**장점:**
- 필요할 때만 버킷 분할
- 전체 재해싱 불필요
- 공간 효율적

**단점:**
- 디렉토리가 메모리에 있어야 효율적
- 디렉토리 크기가 2의 거듭제곱으로 증가

### 4. Linear Hashing

점진적으로 버킷을 분할하여 확장:

```
┌─────────────────────────────────────────────────────────────┐
│                  Linear Hashing                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│ 핵심 아이디어:                                               │
│ - 디렉토리 없이 순차적으로 버킷 분할                         │
│ - Split Pointer가 다음 분할할 버킷 지정                      │
│ - 두 개의 해시 함수 h0, h1 사용                             │
│                                                             │
│ Level = 0, N = 4, Split = 0                                 │
│                                                             │
│ h0(k) = k mod 4                                             │
│ h1(k) = k mod 8  (다음 레벨)                                │
│                                                             │
│ ┌─────────────────────────────────────────┐                │
│ │ 0 │ 1 │ 2 │ 3 │   ← 현재 버킷들         │                │
│ └─────────────────────────────────────────┘                │
│   ↑                                                         │
│ Split                                                       │
│                                                             │
│ 검색: b = h0(k)                                             │
│       if b < split: b = h1(k)                               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**분할 과정:**

```
Split = 0, 버킷 0 분할

Before:
│ 0:[0,4,8,12] │ 1:[1,5,9] │ 2:[2,6] │ 3:[3,7] │

버킷 0을 h1(k) = k mod 8로 재분배:
- 0, 8 → 버킷 0 (mod 8 = 0)
- 4, 12 → 버킷 4 (mod 8 = 4)

After:
│ 0:[0,8] │ 1:[1,5,9] │ 2:[2,6] │ 3:[3,7] │ 4:[4,12] │
                                             ↑
Split = 1                                   새 버킷

모든 버킷 분할되면 Level++, Split = 0
```

**장점:**
- 점진적 확장 (한 번에 하나씩)
- 디렉토리 불필요
- 균일한 분할

**단점:**
- 분할 순서가 고정됨 (가득 찬 버킷이 아닌 split 위치 분할)
- 일시적으로 오버플로 체인 사용

### 5. Cuckoo Hashing

두 개의 해시 함수로 충돌을 해결:

```
┌─────────────────────────────────────────────────────────────┐
│                    Cuckoo Hashing                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│ 두 해시 테이블 T1, T2와 두 해시 함수 h1, h2                 │
│                                                             │
│ 삽입(x):                                                    │
│ 1. T1[h1(x)]가 비었으면 삽입                                │
│ 2. 아니면 기존 값 y를 밀어내고 x 삽입                        │
│ 3. y를 T2[h2(y)]에 삽입 시도                                │
│ 4. 충돌 시 다시 밀어내기 반복                                │
│ 5. 사이클 발생하면 재해싱                                    │
│                                                             │
│ T1:         T2:                                              │
│ ┌───┐       ┌───┐                                           │
│ │ A │←h1(A) │ B │←h2(B)                                     │
│ │ - │       │ - │                                           │
│ │ C │←h1(C) │ D │←h2(D)                                     │
│ └───┘       └───┘                                           │
│                                                             │
│ 검색: O(1) - T1[h1(x)] 또는 T2[h2(x)] 확인                  │
│ 삽입: 평균 O(1), 최악 O(N) (재해싱 시)                       │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**장점:**
- 최악의 경우에도 검색 O(1)
- 높은 적재율에서도 성능 유지

**단점:**
- 삽입 시 연쇄 이동 가능
- 사이클 발생 시 재해싱 필요

### 6. B+Tree vs Hash Index 비교

```
┌─────────────────────────────────────────────────────────────┐
│             B+Tree vs Hash Index                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│ 연산           │  B+Tree     │  Hash Index                  │
│ ──────────────┼─────────────┼──────────────                │
│ 등호 검색     │  O(log N)   │  O(1) 평균                   │
│ 범위 검색     │  O(log N+k) │  불가능                      │
│ 정렬 순서     │  지원       │  불가능                      │
│ 삽입/삭제     │  O(log N)   │  O(1) 평균                   │
│ 공간 효율     │  중간       │  낮음 (빈 버킷)              │
│ 동적 확장     │  자연스러움 │  재해싱 필요                 │
│                                                             │
│ 결론:                                                        │
│ - 대부분의 경우 B+Tree 선호                                  │
│ - 해시는 순수 등호 검색 + 높은 트래픽에만 고려               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 7. 실제 DBMS에서의 해시 인덱스

**PostgreSQL:**

```sql
-- 해시 인덱스 생성 (PostgreSQL 10+에서 WAL 지원)
CREATE INDEX idx_hash ON table USING hash (column);

-- 제한사항:
-- - 등호(=) 검색만 지원
-- - 범위, 정렬, LIKE 불가
-- - 유니크 제약 불가

-- 확인
SELECT * FROM pg_indexes WHERE indexdef LIKE '%hash%';
```

**MySQL InnoDB:**

```sql
-- InnoDB는 B+Tree만 지원
-- MEMORY 엔진에서 해시 인덱스 사용 가능
CREATE TABLE temp_table (
    id INT,
    name VARCHAR(50),
    INDEX USING HASH (id)
) ENGINE = MEMORY;

-- Adaptive Hash Index (자동)
-- InnoDB가 자주 접근하는 인덱스 페이지에 자동으로 해시 인덱스 구축
SHOW ENGINE INNODB STATUS;  -- Hash table size 확인
```

### 8. Adaptive Hash Index (MySQL InnoDB)

```
┌─────────────────────────────────────────────────────────────┐
│           InnoDB Adaptive Hash Index                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│ B+Tree 인덱스 위에 자동으로 구축되는 해시 인덱스            │
│                                                             │
│   Query → [Adaptive Hash] → Page                            │
│              없으면 ↓                                        │
│           [B+Tree 탐색]                                      │
│                                                             │
│ 조건:                                                        │
│ - 같은 인덱스 페이지에 반복 접근                            │
│ - 자동으로 해시 엔트리 생성                                  │
│                                                             │
│ 장점: 자주 접근하는 페이지 O(1) 접근                         │
│ 단점: 메모리 사용, 동시성 이슈 가능                          │
│                                                             │
│ 설정:                                                        │
│ innodb_adaptive_hash_index = ON (기본)                      │
│ innodb_adaptive_hash_index_parts = 8 (파티션)               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

## 실무 적용

### 해시 인덱스 사용 판단

```sql
-- 해시 인덱스 적합한 경우:
-- 1. 순수 등호 검색만 수행
-- 2. 범위 검색, 정렬 불필요
-- 3. 매우 높은 읽기 트래픽

-- 예: 세션 ID 검색
CREATE TABLE sessions (
    session_id VARCHAR(64) PRIMARY KEY,
    user_id INT,
    data JSONB
);

-- PostgreSQL
CREATE INDEX idx_session ON sessions USING hash (session_id);

-- 사용 시
SELECT * FROM sessions WHERE session_id = 'abc123';  -- 해시 사용 가능
SELECT * FROM sessions WHERE session_id LIKE 'abc%'; -- 사용 불가
```

### 해시 함수 선택

```
좋은 해시 함수 특성:
1. 균등 분포: 모든 버킷에 균등하게 분배
2. 결정적: 같은 입력 → 같은 출력
3. 빠른 계산: O(키 길이)

일반적 해시 함수:
- MurmurHash: 빠르고 균등
- xxHash: 매우 빠름
- CityHash: Google 개발, 문자열에 최적화
```

## 참고 자료

- "Database System Concepts" (Silberschatz) - Chapter 14
- CMU 15-445: Hash Tables
- "Database Internals" (Petrov) - Chapter 7
- PostgreSQL Documentation: Hash Indexes
- MySQL Documentation: InnoDB Adaptive Hash Index
