# 점근적 분석 (Asymptotic Analysis)

## 개요

점근적 분석은 알고리즘의 효율성을 입력 크기가 무한대로 커질 때의 성장률로 표현하는 수학적 방법이다. 상수 계수와 낮은 차수의 항을 무시하고, 알고리즘의 본질적인 성능 특성을 파악할 수 있게 해준다.

### 왜 점근적 분석을 사용하는가?

1. **하드웨어 독립성**: 실행 시간이 아닌 연산 횟수로 분석하여 하드웨어에 독립적인 비교 가능
2. **확장성 예측**: 입력 크기가 커질 때 알고리즘의 동작 예측 가능
3. **단순성**: 상수와 저차항을 무시하여 핵심 성능 특성에 집중

## 핵심 개념

### Big-O 표기법 (상한)

**정의**: f(n) = O(g(n))이면, 양의 상수 c와 n₀가 존재하여 모든 n ≥ n₀에 대해 0 ≤ f(n) ≤ c·g(n)

```
수학적 정의:
f(n) = O(g(n)) ⟺ ∃c > 0, ∃n₀ > 0 : ∀n ≥ n₀, 0 ≤ f(n) ≤ c·g(n)
```

**직관적 의미**: f(n)은 g(n)보다 "빠르게 증가하지 않는다" (최악의 경우 상한)

**예시 증명**: 2n² + 3n + 1 = O(n²)

```
증명:
2n² + 3n + 1 ≤ 2n² + 3n² + n² = 6n² (n ≥ 1일 때)
따라서 c = 6, n₀ = 1로 설정하면 조건 만족
∴ 2n² + 3n + 1 = O(n²)
```

### Big-Ω 표기법 (하한)

**정의**: f(n) = Ω(g(n))이면, 양의 상수 c와 n₀가 존재하여 모든 n ≥ n₀에 대해 0 ≤ c·g(n) ≤ f(n)

```
수학적 정의:
f(n) = Ω(g(n)) ⟺ ∃c > 0, ∃n₀ > 0 : ∀n ≥ n₀, 0 ≤ c·g(n) ≤ f(n)
```

**직관적 의미**: f(n)은 g(n)보다 "느리게 증가하지 않는다" (최선의 경우 하한)

**예시 증명**: 2n² + 3n + 1 = Ω(n²)

```
증명:
2n² + 3n + 1 ≥ 2n² (n ≥ 1일 때)
따라서 c = 2, n₀ = 1로 설정하면 조건 만족
∴ 2n² + 3n + 1 = Ω(n²)
```

### Big-Θ 표기법 (타이트 바운드)

**정의**: f(n) = Θ(g(n))이면, f(n) = O(g(n))이고 f(n) = Ω(g(n))

```
수학적 정의:
f(n) = Θ(g(n)) ⟺ ∃c₁ > 0, ∃c₂ > 0, ∃n₀ > 0 : ∀n ≥ n₀, c₁·g(n) ≤ f(n) ≤ c₂·g(n)
```

**직관적 의미**: f(n)과 g(n)은 "같은 속도로 증가한다" (정확한 증가율)

**예시 증명**: 2n² + 3n + 1 = Θ(n²)

```
증명:
상한: 2n² + 3n + 1 ≤ 6n² (위에서 증명)
하한: 2n² + 3n + 1 ≥ 2n² (위에서 증명)
따라서 c₁ = 2, c₂ = 6, n₀ = 1로 설정하면 조건 만족
∴ 2n² + 3n + 1 = Θ(n²)
```

### Little-o 표기법 (엄격한 상한)

**정의**: f(n) = o(g(n))이면, 모든 양의 상수 c에 대해 n₀가 존재하여 모든 n ≥ n₀에 대해 0 ≤ f(n) < c·g(n)

```
수학적 정의:
f(n) = o(g(n)) ⟺ lim(n→∞) f(n)/g(n) = 0
```

**직관적 의미**: f(n)은 g(n)보다 "엄격하게 느리게 증가한다"

**예시**: n = o(n²), n log n = o(n²), n² = o(n³)

### Little-ω 표기법 (엄격한 하한)

**정의**: f(n) = ω(g(n))이면, 모든 양의 상수 c에 대해 n₀가 존재하여 모든 n ≥ n₀에 대해 0 ≤ c·g(n) < f(n)

```
수학적 정의:
f(n) = ω(g(n)) ⟺ lim(n→∞) f(n)/g(n) = ∞
```

**직관적 의미**: f(n)은 g(n)보다 "엄격하게 빠르게 증가한다"

**예시**: n² = ω(n), n³ = ω(n²)

### 점근적 표기법의 성질

#### 1. Transitivity (이행성)

```
f(n) = O(g(n)) ∧ g(n) = O(h(n)) ⟹ f(n) = O(h(n))
f(n) = Ω(g(n)) ∧ g(n) = Ω(h(n)) ⟹ f(n) = Ω(h(n))
f(n) = Θ(g(n)) ∧ g(n) = Θ(h(n)) ⟹ f(n) = Θ(h(n))
f(n) = o(g(n)) ∧ g(n) = o(h(n)) ⟹ f(n) = o(h(n))
f(n) = ω(g(n)) ∧ g(n) = ω(h(n)) ⟹ f(n) = ω(h(n))
```

#### 2. Reflexivity (반사성)

```
f(n) = O(f(n))
f(n) = Ω(f(n))
f(n) = Θ(f(n))
```

#### 3. Symmetry (대칭성)

```
f(n) = Θ(g(n)) ⟺ g(n) = Θ(f(n))
```

#### 4. Transpose Symmetry (전치 대칭성)

```
f(n) = O(g(n)) ⟺ g(n) = Ω(f(n))
f(n) = o(g(n)) ⟺ g(n) = ω(f(n))
```

### 표기법 간 관계

```
관계 비유:
O  ≈  ≤   (이하)
Ω  ≈  ≥   (이상)
Θ  ≈  =   (같음)
o  ≈  <   (미만)
ω  ≈  >   (초과)
```

### 자주 사용되는 점근적 분석 기법

#### 1. 다항식 판정

```
p(n) = aₖnᵏ + aₖ₋₁nᵏ⁻¹ + ... + a₁n + a₀ (aₖ > 0)

이면 p(n) = Θ(nᵏ)
```

#### 2. 로그 법칙

```
log_a(n) = Θ(log_b(n))  (모든 양의 상수 a, b > 1에 대해)
→ 밑이 무엇이든 로그의 점근적 복잡도는 동일
```

#### 3. 지수 vs 다항식

```
nᵏ = o(aⁿ) (a > 1, k ≥ 0)
→ 어떤 다항식도 지수 함수보다 느리게 증가
```

#### 4. 로그 vs 다항식

```
logᵏ(n) = o(nᵉ) (k, ε > 0)
→ 어떤 로그 거듭제곱도 다항식보다 느리게 증가
```

## 실무 적용

### 복잡도 비교 시 주의점

```java
// 예시: 두 알고리즘의 실제 비교
// 알고리즘 A: 1000n
// 알고리즘 B: n²

// 점근적으로 A가 더 낫지만 (O(n) < O(n²))
// n < 1000일 때는 B가 실제로 더 빠를 수 있음

// n = 100일 때:
// A: 1000 * 100 = 100,000
// B: 100² = 10,000  ← 실제로 더 빠름

// n = 10000일 때:
// A: 1000 * 10000 = 10,000,000
// B: 10000² = 100,000,000  ← 점근적 분석이 맞음
```

### 상수 계수가 중요한 경우

```python
# 캐시 효율성 등으로 상수 계수가 큰 차이를 만들 수 있음

# 배열 순회 (캐시 친화적)
def sum_array(arr):
    total = 0
    for x in arr:  # 연속 메모리 접근
        total += x
    return total

# 연결 리스트 순회 (캐시 비친화적)
def sum_linked_list(head):
    total = 0
    node = head
    while node:  # 흩어진 메모리 접근
        total += node.val
        node = node.next
    return total

# 둘 다 O(n)이지만, 배열 버전이 상수 배 더 빠를 수 있음
```

### 점근적 분석의 한계

1. **작은 입력**: 점근적 우위가 실제 성능 우위를 보장하지 않음
2. **상수 계수**: 실제 성능에 큰 영향을 미칠 수 있음
3. **메모리 계층**: 캐시 효과를 반영하지 않음
4. **최악 vs 평균**: 실제 사용 패턴과 다를 수 있음

## 참고 자료

- Introduction to Algorithms (CLRS), Chapter 3: Growth of Functions
- MIT OCW 6.006 Lecture 2: Asymptotic Complexity
- Sedgewick's Algorithms, Section 1.4: Analysis of Algorithms
